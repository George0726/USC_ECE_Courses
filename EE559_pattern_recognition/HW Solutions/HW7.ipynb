{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EE559 HW7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qirui Sun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Multi-class and Multi-Label ClassiÔ¨Åcation Using Support Vector Machines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Download the Anuran Calls (MFCCs) Data Set from: https://archive.ics.uci.edu/ml/datasets/Anuran+Calls+%28MFCCs). Choose 70% of the data randomly as the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5036, 22) (2159, 22)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('Frogs_MFCCs.csv')\n",
    "\n",
    "x_key = []\n",
    "y_key = []\n",
    "\n",
    "for key in df:\n",
    "    if \"MFCCs\" in  key:\n",
    "        x_key.append(key)\n",
    "    elif key != 'RecordID':\n",
    "        y_key.append(key)\n",
    "\n",
    "X = df[x_key]\n",
    "y = df[y_key]\n",
    "\n",
    "X_train,X_test, Y_train, Y_test = train_test_split(X,y,test_size=0.3, random_state=0)\n",
    "\n",
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCCs_ 1</th>\n",
       "      <th>MFCCs_ 2</th>\n",
       "      <th>MFCCs_ 3</th>\n",
       "      <th>MFCCs_ 4</th>\n",
       "      <th>MFCCs_ 5</th>\n",
       "      <th>MFCCs_ 6</th>\n",
       "      <th>MFCCs_ 7</th>\n",
       "      <th>MFCCs_ 8</th>\n",
       "      <th>MFCCs_ 9</th>\n",
       "      <th>MFCCs_10</th>\n",
       "      <th>...</th>\n",
       "      <th>MFCCs_13</th>\n",
       "      <th>MFCCs_14</th>\n",
       "      <th>MFCCs_15</th>\n",
       "      <th>MFCCs_16</th>\n",
       "      <th>MFCCs_17</th>\n",
       "      <th>MFCCs_18</th>\n",
       "      <th>MFCCs_19</th>\n",
       "      <th>MFCCs_20</th>\n",
       "      <th>MFCCs_21</th>\n",
       "      <th>MFCCs_22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.110506</td>\n",
       "      <td>0.296575</td>\n",
       "      <td>0.572484</td>\n",
       "      <td>0.106014</td>\n",
       "      <td>0.071651</td>\n",
       "      <td>0.026353</td>\n",
       "      <td>-0.057816</td>\n",
       "      <td>0.152764</td>\n",
       "      <td>0.184266</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003411</td>\n",
       "      <td>0.122159</td>\n",
       "      <td>0.188889</td>\n",
       "      <td>-0.048002</td>\n",
       "      <td>-0.197944</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.106280</td>\n",
       "      <td>-0.000289</td>\n",
       "      <td>-0.030885</td>\n",
       "      <td>-0.013138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.220624</td>\n",
       "      <td>0.242714</td>\n",
       "      <td>0.687612</td>\n",
       "      <td>0.278120</td>\n",
       "      <td>0.048901</td>\n",
       "      <td>-0.175033</td>\n",
       "      <td>0.045482</td>\n",
       "      <td>0.194987</td>\n",
       "      <td>-0.026137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239639</td>\n",
       "      <td>-0.258718</td>\n",
       "      <td>-0.181393</td>\n",
       "      <td>0.224083</td>\n",
       "      <td>0.189132</td>\n",
       "      <td>-0.086415</td>\n",
       "      <td>-0.142950</td>\n",
       "      <td>-0.061968</td>\n",
       "      <td>0.140081</td>\n",
       "      <td>0.177679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6530</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.537389</td>\n",
       "      <td>0.411925</td>\n",
       "      <td>0.220964</td>\n",
       "      <td>0.082649</td>\n",
       "      <td>0.116707</td>\n",
       "      <td>0.030271</td>\n",
       "      <td>-0.025917</td>\n",
       "      <td>0.095736</td>\n",
       "      <td>0.055280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071234</td>\n",
       "      <td>-0.047150</td>\n",
       "      <td>-0.027571</td>\n",
       "      <td>0.040844</td>\n",
       "      <td>0.008839</td>\n",
       "      <td>0.020528</td>\n",
       "      <td>0.032644</td>\n",
       "      <td>-0.030302</td>\n",
       "      <td>-0.009163</td>\n",
       "      <td>0.073411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4445</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.113471</td>\n",
       "      <td>0.141275</td>\n",
       "      <td>0.510700</td>\n",
       "      <td>0.171047</td>\n",
       "      <td>0.004309</td>\n",
       "      <td>-0.152609</td>\n",
       "      <td>-0.014724</td>\n",
       "      <td>0.187484</td>\n",
       "      <td>-0.021925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231469</td>\n",
       "      <td>-0.201889</td>\n",
       "      <td>-0.133748</td>\n",
       "      <td>0.223116</td>\n",
       "      <td>0.169808</td>\n",
       "      <td>-0.124180</td>\n",
       "      <td>-0.159812</td>\n",
       "      <td>-0.033042</td>\n",
       "      <td>0.185773</td>\n",
       "      <td>0.165372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4218</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.240949</td>\n",
       "      <td>0.216480</td>\n",
       "      <td>0.461523</td>\n",
       "      <td>0.117414</td>\n",
       "      <td>-0.062445</td>\n",
       "      <td>-0.130187</td>\n",
       "      <td>0.112749</td>\n",
       "      <td>0.340813</td>\n",
       "      <td>0.070309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266955</td>\n",
       "      <td>-0.147366</td>\n",
       "      <td>-0.291212</td>\n",
       "      <td>0.032346</td>\n",
       "      <td>0.178339</td>\n",
       "      <td>0.043587</td>\n",
       "      <td>-0.123294</td>\n",
       "      <td>-0.113868</td>\n",
       "      <td>0.099137</td>\n",
       "      <td>0.182885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.142398</td>\n",
       "      <td>-0.135605</td>\n",
       "      <td>0.489808</td>\n",
       "      <td>0.346600</td>\n",
       "      <td>0.112585</td>\n",
       "      <td>0.022297</td>\n",
       "      <td>-0.050188</td>\n",
       "      <td>-0.039155</td>\n",
       "      <td>0.179645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139727</td>\n",
       "      <td>0.206907</td>\n",
       "      <td>0.180459</td>\n",
       "      <td>-0.081065</td>\n",
       "      <td>-0.159301</td>\n",
       "      <td>-0.052028</td>\n",
       "      <td>0.050629</td>\n",
       "      <td>0.090996</td>\n",
       "      <td>0.076187</td>\n",
       "      <td>-0.029321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.176691</td>\n",
       "      <td>0.010582</td>\n",
       "      <td>0.426816</td>\n",
       "      <td>0.159823</td>\n",
       "      <td>0.082286</td>\n",
       "      <td>-0.081110</td>\n",
       "      <td>0.071147</td>\n",
       "      <td>0.316694</td>\n",
       "      <td>0.125304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285737</td>\n",
       "      <td>0.008472</td>\n",
       "      <td>-0.254754</td>\n",
       "      <td>0.020172</td>\n",
       "      <td>0.245519</td>\n",
       "      <td>0.135507</td>\n",
       "      <td>-0.092764</td>\n",
       "      <td>-0.155646</td>\n",
       "      <td>0.041699</td>\n",
       "      <td>0.261644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>0.689976</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.303498</td>\n",
       "      <td>0.320465</td>\n",
       "      <td>0.206091</td>\n",
       "      <td>0.334999</td>\n",
       "      <td>0.091622</td>\n",
       "      <td>0.184121</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>0.002416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084504</td>\n",
       "      <td>0.019744</td>\n",
       "      <td>-0.110357</td>\n",
       "      <td>-0.097476</td>\n",
       "      <td>-0.036028</td>\n",
       "      <td>-0.066845</td>\n",
       "      <td>-0.007471</td>\n",
       "      <td>-0.004674</td>\n",
       "      <td>0.035157</td>\n",
       "      <td>0.028860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.378678</td>\n",
       "      <td>0.430880</td>\n",
       "      <td>0.618243</td>\n",
       "      <td>0.075128</td>\n",
       "      <td>-0.008888</td>\n",
       "      <td>-0.106768</td>\n",
       "      <td>0.067784</td>\n",
       "      <td>0.266808</td>\n",
       "      <td>-0.084165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366652</td>\n",
       "      <td>-0.177005</td>\n",
       "      <td>-0.321548</td>\n",
       "      <td>0.112632</td>\n",
       "      <td>0.199011</td>\n",
       "      <td>-0.030374</td>\n",
       "      <td>-0.083440</td>\n",
       "      <td>-0.081388</td>\n",
       "      <td>0.101548</td>\n",
       "      <td>0.165429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.234852</td>\n",
       "      <td>0.521376</td>\n",
       "      <td>0.604825</td>\n",
       "      <td>-0.005588</td>\n",
       "      <td>-0.019032</td>\n",
       "      <td>-0.105843</td>\n",
       "      <td>0.021297</td>\n",
       "      <td>0.223438</td>\n",
       "      <td>0.036097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245400</td>\n",
       "      <td>-0.033537</td>\n",
       "      <td>-0.222563</td>\n",
       "      <td>-0.005953</td>\n",
       "      <td>0.164287</td>\n",
       "      <td>0.070412</td>\n",
       "      <td>-0.103183</td>\n",
       "      <td>-0.154838</td>\n",
       "      <td>-0.001597</td>\n",
       "      <td>0.121950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5036 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
       "854   1.000000 -0.110506  0.296575  0.572484  0.106014  0.071651  0.026353   \n",
       "4279  1.000000  0.220624  0.242714  0.687612  0.278120  0.048901 -0.175033   \n",
       "6530  1.000000  0.537389  0.411925  0.220964  0.082649  0.116707  0.030271   \n",
       "4445  1.000000  0.113471  0.141275  0.510700  0.171047  0.004309 -0.152609   \n",
       "4218  1.000000  0.240949  0.216480  0.461523  0.117414 -0.062445 -0.130187   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4931  1.000000 -0.142398 -0.135605  0.489808  0.346600  0.112585  0.022297   \n",
       "3264  1.000000  0.176691  0.010582  0.426816  0.159823  0.082286 -0.081110   \n",
       "1653  0.689976  1.000000  0.303498  0.320465  0.206091  0.334999  0.091622   \n",
       "2607  1.000000  0.378678  0.430880  0.618243  0.075128 -0.008888 -0.106768   \n",
       "2732  1.000000  0.234852  0.521376  0.604825 -0.005588 -0.019032 -0.105843   \n",
       "\n",
       "      MFCCs_ 8  MFCCs_ 9  MFCCs_10  ...  MFCCs_13  MFCCs_14  MFCCs_15  \\\n",
       "854  -0.057816  0.152764  0.184266  ... -0.003411  0.122159  0.188889   \n",
       "4279  0.045482  0.194987 -0.026137  ...  0.239639 -0.258718 -0.181393   \n",
       "6530 -0.025917  0.095736  0.055280  ...  0.071234 -0.047150 -0.027571   \n",
       "4445 -0.014724  0.187484 -0.021925  ...  0.231469 -0.201889 -0.133748   \n",
       "4218  0.112749  0.340813  0.070309  ...  0.266955 -0.147366 -0.291212   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4931 -0.050188 -0.039155  0.179645  ... -0.139727  0.206907  0.180459   \n",
       "3264  0.071147  0.316694  0.125304  ...  0.285737  0.008472 -0.254754   \n",
       "1653  0.184121  0.004056  0.002416  ...  0.084504  0.019744 -0.110357   \n",
       "2607  0.067784  0.266808 -0.084165  ...  0.366652 -0.177005 -0.321548   \n",
       "2732  0.021297  0.223438  0.036097  ...  0.245400 -0.033537 -0.222563   \n",
       "\n",
       "      MFCCs_16  MFCCs_17  MFCCs_18  MFCCs_19  MFCCs_20  MFCCs_21  MFCCs_22  \n",
       "854  -0.048002 -0.197944  0.002446  0.106280 -0.000289 -0.030885 -0.013138  \n",
       "4279  0.224083  0.189132 -0.086415 -0.142950 -0.061968  0.140081  0.177679  \n",
       "6530  0.040844  0.008839  0.020528  0.032644 -0.030302 -0.009163  0.073411  \n",
       "4445  0.223116  0.169808 -0.124180 -0.159812 -0.033042  0.185773  0.165372  \n",
       "4218  0.032346  0.178339  0.043587 -0.123294 -0.113868  0.099137  0.182885  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4931 -0.081065 -0.159301 -0.052028  0.050629  0.090996  0.076187 -0.029321  \n",
       "3264  0.020172  0.245519  0.135507 -0.092764 -0.155646  0.041699  0.261644  \n",
       "1653 -0.097476 -0.036028 -0.066845 -0.007471 -0.004674  0.035157  0.028860  \n",
       "2607  0.112632  0.199011 -0.030374 -0.083440 -0.081388  0.101548  0.165429  \n",
       "2732 -0.005953  0.164287  0.070412 -0.103183 -0.154838 -0.001597  0.121950  \n",
       "\n",
       "[5036 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Each instance has three labels: Families, Genus, and Species. Each of the labels has multiple classes. We wish to sol/ve a multi-class and multi-label problem. One of the most important approaches to multi-class classiÔ¨Åcation is to train a classiÔ¨Åer for each label. We Ô¨Årst try this approach: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### i. Research exact match and hamming score/ loss methods for evaluating multilabel classiÔ¨Åcation and use them in evaluating the classiÔ¨Åers in this problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics in sklearn package. use $ metrics.accuracy\\_ score(y_{true}, y_{pred})$ to evaluate multilabel classification for an exact match way. And also it has $metrics.hamming\\_loss(y_{true}, y_{pred})$ which could be used to compute the average Hamming loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ii. Train a SVM for each of the labels, using Gaussian kernels and one versus all classiÔ¨Åers. Determine the weight of the SVM penalty and the width of the Gaussian Kernel using 10 fold cross validation. You are welcome to try to solve the problem with both normalized and raw attributes and report the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For Raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Family----------\n",
      "{'C': 251.18864315095823, 'gamma': 1.0}\n",
      "accuracy score: 0.9939786938397406\n",
      "hamming loss: 0.006021306160259379 \n",
      "\n",
      "---------Genus----------\n",
      "{'C': 251.18864315095823, 'gamma': 1.0}\n",
      "accuracy score: 0.9902732746641963\n",
      "hamming loss: 0.009726725335803613 \n",
      "\n",
      "---------Species----------\n",
      "{'C': 251.18864315095823, 'gamma': 1.0}\n",
      "accuracy score: 0.9902732746641963\n",
      "hamming loss: 0.009726725335803613 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, hamming_loss\n",
    "\n",
    "parameters = {'gamma':np.logspace(-8,2,11),'C':np.logspace(-3,6,6)}\n",
    "\n",
    "for  key in Y_test.columns.values:\n",
    "\n",
    "    y_train = Y_train[key].values\n",
    "    y_test =Y_test[key].values\n",
    "\n",
    "    model = SVC(kernel = 'rbf',decision_function_shape='ovr')\n",
    "    cv_model = GridSearchCV(model,param_grid = parameters,cv = 10, n_jobs = -1)\n",
    "    cv_model.fit(X_train,y_train)\n",
    "    model0 = cv_model.best_estimator_\n",
    "    y_pred = model0.predict(X_test)\n",
    "\n",
    "    print(\"---------%s----------\"%(key))\n",
    "    print(cv_model.best_params_)\n",
    "    print('accuracy score:',accuracy_score(y_test,y_pred))\n",
    "    print('hamming loss:',hamming_loss(y_test,y_pred),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For normalized data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Family----------\n",
      "{'svc__C': 10.0, 'svc__gamma': 0.1}\n",
      "accuracy score: 0.30430754979157015\n",
      "hamming loss: 0.6956924502084298 \n",
      "\n",
      "---------Genus----------\n",
      "{'svc__C': 10.0, 'svc__gamma': 0.1}\n",
      "accuracy score: 0.22510421491431218\n",
      "hamming loss: 0.7748957850856878 \n",
      "\n",
      "---------Species----------\n",
      "{'svc__C': 1000.0, 'svc__gamma': 0.01}\n",
      "accuracy score: 0.09819360815192218\n",
      "hamming loss: 0.9018063918480778 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, hamming_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "parameters = {'svc__gamma':np.logspace(-8,2,11),'svc__C':np.logspace(-3,6,10)}# pass the parameters should have svc\n",
    "pip = Pipeline([(\"standardize\", StandardScaler()),(\"svc\", SVC(kernel=\"rbf\", decision_function_shape='ovr'))])\n",
    "X_test = StandardScaler().fit(X_test).transform(X_test)\n",
    "\n",
    "for  key in Y_test.columns.values:\n",
    "\n",
    "    y_train = Y_train[key].values\n",
    "    y_test = Y_test[key].values\n",
    "\n",
    "    cv_model = GridSearchCV(pip,param_grid = parameters,cv = 10, n_jobs = -1)\n",
    "    cv_model.fit(X_train,y_train)\n",
    "    model0 = cv_model.best_estimator_\n",
    "    y_pred = model0.predict(X_test)\n",
    "\n",
    "    print(\"---------%s----------\"%(key))\n",
    "    print(cv_model.best_params_)\n",
    "    print('accuracy score:',accuracy_score(y_test,y_pred))\n",
    "    print('hamming loss:',hamming_loss(y_test,y_pred),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iii. Repeat 1(b)ii with L1-penalized SVMs.3 Remember to normalize the attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Family----------\n",
      "{'LinearSVC__C': 0.35938136638046275, 'LinearSVC__tol': 3.1622776601683795e-05}\n",
      "accuracy score: 0.8188976377952756\n",
      "hamming loss: 0.18110236220472442 \n",
      "\n",
      "---------Genus----------\n",
      "{'LinearSVC__C': 12.91549665014884, 'LinearSVC__tol': 0.0005623413251903491}\n",
      "accuracy score: 0.666512274201019\n",
      "hamming loss: 0.333487725798981 \n",
      "\n",
      "---------Species----------\n",
      "{'LinearSVC__C': 2.1544346900318843, 'LinearSVC__tol': 0.01}\n",
      "accuracy score: 0.840203798054655\n",
      "hamming loss: 0.15979620194534508 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, hamming_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "parameters = {'LinearSVC__tol':np.logspace(-7,-2,5),'LinearSVC__C':np.logspace(-2, 5, 10)}# pass the parameters should have svc\n",
    "pip = Pipeline([(\"Standardize\", StandardScaler()),(\"LinearSVC\", LinearSVC(penalty = 'l1', multi_class='ovr', dual=False))])\n",
    "\n",
    "for  key in Y_test.columns.values:\n",
    "\n",
    "    y_train = Y_train[key].values\n",
    "    y_test = Y_test[key].values\n",
    "\n",
    "    cv_model = GridSearchCV(pip,param_grid = parameters,cv = 10, n_jobs = -1)\n",
    "    cv_model.fit(X_train,y_train)\n",
    "    model0 = cv_model.best_estimator_\n",
    "    y_pred = model0.predict(X_test)\n",
    "\n",
    "    print(\"---------%s----------\"%(key))\n",
    "    print(cv_model.best_params_)\n",
    "    print('accuracy score:',accuracy_score(y_test,y_pred))\n",
    "    print('hamming loss:',hamming_loss(y_test,y_pred),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iv. Repeat 1(b)iii by using SMOTE or any other method you know to remedy class imbalance. Report your conclusions about the classiÔ¨Åers you trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Family----------\n",
      "{'LinearSVC__C': 0.35938136638046275, 'LinearSVC__tol': 1e-07}\n",
      "accuracy score: 0.5247799907364521\n",
      "hamming loss: 0.47522000926354796 \n",
      "\n",
      "---------Genus----------\n",
      "{'LinearSVC__C': 2.1544346900318843, 'LinearSVC__tol': 1e-07}\n",
      "accuracy score: 0.5030106530801297\n",
      "hamming loss: 0.4969893469198703 \n",
      "\n",
      "---------Species----------\n",
      "{'LinearSVC__C': 77.4263682681127, 'LinearSVC__tol': 1e-06}\n",
      "accuracy score: 0.651227420101899\n",
      "hamming loss: 0.34877257989810095 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, hamming_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "X_train,X_test, Y_train, Y_test = train_test_split(X,y,test_size=0.3, random_state=0)\n",
    "X_test = StandardScaler().fit(X_test).transform(X_test)\n",
    "\n",
    "parameters = {'LinearSVC__tol':np.logspace(-7,-3,5),'LinearSVC__C':np.logspace(-2, 5, 10)}# pass the parameters should have svc\n",
    "pip = Pipeline([(\"Standardize\", StandardScaler()),(\"LinearSVC\", LinearSVC(penalty = 'l1', multi_class='ovr', dual=False))])\n",
    "\n",
    "for  key in Y_test.columns.values:\n",
    "\n",
    "    y_train = Y_train[key].values\n",
    "    y_test = Y_test[key].values\n",
    "    \n",
    "    smo = SMOTE(random_state = 26)\n",
    "    X_train_balance,y_train_balance = smo.fit_sample(X_train,y_train)\n",
    "\n",
    "    cv_model = GridSearchCV(pip,param_grid = parameters,cv = 10, n_jobs = -1)\n",
    "    cv_model.fit(X_train_balance,y_train_balance)\n",
    "    model0 = cv_model.best_estimator_\n",
    "    y_pred = model0.predict(X_test)\n",
    "\n",
    "    print(\"---------%s----------\"%(key))\n",
    "    print(cv_model.best_params_)\n",
    "    print('accuracy score:',accuracy_score(y_test,y_pred))\n",
    "    print('hamming loss:',hamming_loss(y_test,y_pred),'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
